{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10092630,"sourceType":"datasetVersion","datasetId":4987536}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Conv1D, MaxPooling1D\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport concurrent.futures\nfrom tqdm import tqdm\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, LSTM, Conv1D, MaxPooling1D, GRU\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import mean_squared_error\nfrom tensorflow.keras.models import model_from_json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:53:17.281392Z","iopub.execute_input":"2024-12-04T18:53:17.281780Z","iopub.status.idle":"2024-12-04T18:53:31.942576Z","shell.execute_reply.started":"2024-12-04T18:53:17.281747Z","shell.execute_reply":"2024-12-04T18:53:31.941657Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pre processsinng","metadata":{}},{"cell_type":"code","source":"def preprocess_stock_data(file_path, stock_name):\n    df = pd.read_csv(file_path)\n    df['stockname'] = df['stockname'].str.strip().str.upper()\n    stock_name = stock_name.strip().upper()\n    filtered_df = df[df['stockname'] == stock_name]\n    if filtered_df.empty:\n        raise ValueError(f\"No data found for the stock '{stock_name}'. Please check the name.\")\n    filtered_df['timestamp'] = pd.to_datetime(filtered_df['timestamp'])\n    filtered_df = filtered_df.sort_values(by='timestamp')\n    imputer = SimpleImputer(strategy='mean')\n    numeric_cols = filtered_df.select_dtypes(include=['float64', 'int64']).columns\n    filtered_df[numeric_cols] = imputer.fit_transform(filtered_df[numeric_cols])\n    filtered_df['moving_average'] = filtered_df['high'].rolling(window=5).mean()\n    filtered_df['std_dev'] = filtered_df['high'].rolling(window=5).std()\n    filtered_df.fillna(method='bfill', inplace=True)  \n    return filtered_df\n\ndef prepare_lstm_data(df, lookback=60):\n    scaler = MinMaxScaler()\n    scaled_data = scaler.fit_transform(df[['high', 'low', 'moving_average', 'std_dev']])\n    X, y = [], []\n    for i in range(lookback, len(scaled_data)):\n        X.append(scaled_data[i-lookback:i]) \n        y.append(scaled_data[i, [0, 1]])  \n    X, y = np.array(X), np.array(y)\n    return X, y, scaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:53:31.944637Z","iopub.execute_input":"2024-12-04T18:53:31.945346Z","iopub.status.idle":"2024-12-04T18:53:31.955029Z","shell.execute_reply.started":"2024-12-04T18:53:31.945282Z","shell.execute_reply":"2024-12-04T18:53:31.954119Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"def create_dnn_lstm_model(input_shape):\n    model = Sequential([\n        Dense(128, activation='relu', input_shape=input_shape),\n        Dropout(0.3),\n        LSTM(128, return_sequences=False),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(2)  \n    ])\n    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error')\n    return model\n\ndef create_cnn_lstm_model(input_shape):\n    model = Sequential([\n        Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n        MaxPooling1D(pool_size=2),\n        LSTM(128, return_sequences=False),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(2) \n    ])\n    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error')\n    return model\n\ndef create_gru_lstm_model(input_shape):\n    model = Sequential([\n        GRU(128, return_sequences=True, input_shape=input_shape),\n        Dropout(0.3),\n        LSTM(128, return_sequences=False),\n        Dropout(0.3),\n        Dense(64, activation='relu'),\n        Dropout(0.2),\n        Dense(2)  \n    ])\n    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error')\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:53:31.956014Z","iopub.execute_input":"2024-12-04T18:53:31.956395Z","iopub.status.idle":"2024-12-04T18:53:32.047323Z","shell.execute_reply.started":"2024-12-04T18:53:31.956317Z","shell.execute_reply":"2024-12-04T18:53:32.046379Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# supporter","metadata":{}},{"cell_type":"code","source":"def find_exact_date(df, target_date):\n    target_date = pd.to_datetime(target_date).normalize()\n    if target_date in df['timestamp'].dt.normalize().values:\n        return target_date\n    else:\n        raise ValueError(f\"No data available for the exact date {target_date.date()}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:53:32.049382Z","iopub.execute_input":"2024-12-04T18:53:32.049759Z","iopub.status.idle":"2024-12-04T18:53:32.061635Z","shell.execute_reply.started":"2024-12-04T18:53:32.049711Z","shell.execute_reply":"2024-12-04T18:53:32.060697Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"data = preprocess_stock_data('/kaggle/input/stock-past-one-year-data/stocks.csv', 'CSX')\nprediction_date = '2024-11-15'\nprediction_date = pd.to_datetime(prediction_date).normalize()\n    \ntry:\n    exact_date = find_exact_date(data, prediction_date)\n    print(f\"Using the exact available date: {exact_date.date()} for prediction.\")\nexcept ValueError as e:\n    print(e)\n    exit()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:53:32.062953Z","iopub.execute_input":"2024-12-04T18:53:32.063266Z","iopub.status.idle":"2024-12-04T18:53:34.588932Z","shell.execute_reply.started":"2024-12-04T18:53:32.063237Z","shell.execute_reply":"2024-12-04T18:53:34.587859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = data[data['timestamp'] < exact_date]\ntest_data = data[data['timestamp'].dt.normalize() == exact_date]\n    \nif test_data.empty:\n    raise ValueError(f\"No data available for the prediction date: {exact_date.date()}\")\n    \nX_train, y_train, scaler = prepare_lstm_data(train_data, lookback=60)\nX_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:53:34.590083Z","iopub.execute_input":"2024-12-04T18:53:34.590425Z","iopub.status.idle":"2024-12-04T18:53:34.619805Z","shell.execute_reply.started":"2024-12-04T18:53:34.590391Z","shell.execute_reply":"2024-12-04T18:53:34.618955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = {\n    'dnn_lstm': create_dnn_lstm_model((X_train.shape[1], X_train.shape[2])),\n    'cnn_lstm': create_cnn_lstm_model((X_train.shape[1], X_train.shape[2])),\n    'gru_lstm': create_gru_lstm_model((X_train.shape[1], X_train.shape[2])),\n}\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:53:34.621072Z","iopub.execute_input":"2024-12-04T18:53:34.621498Z","iopub.status.idle":"2024-12-04T18:53:36.157288Z","shell.execute_reply.started":"2024-12-04T18:53:34.621437Z","shell.execute_reply":"2024-12-04T18:53:36.156231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(name, model):\n    print(f\"Training model: {name}\")\n    history = model.fit(\n        X_train, y_train, \n        epochs=100, \n        batch_size=32, \n        validation_split=0.2, \n        callbacks=[early_stopping],\n        verbose=1\n    )\n    return name, history\n\nhistories = {}\n\n# Use ThreadPoolExecutor to train models in parallel\nwith concurrent.futures.ThreadPoolExecutor() as executor:\n    futures = {\n        executor.submit(train_model, name, model): name \n        for name, model in models.items()\n    }\n    for future in concurrent.futures.as_completed(futures):\n        name, history = future.result()\n        histories[name] = history","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:53:36.158925Z","iopub.execute_input":"2024-12-04T18:53:36.159358Z","iopub.status.idle":"2024-12-04T18:54:19.221666Z","shell.execute_reply.started":"2024-12-04T18:53:36.159312Z","shell.execute_reply":"2024-12-04T18:54:19.220591Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# test","metadata":{}},{"cell_type":"code","source":"# X_test, _, _ = prepare_lstm_data(pd.concat([train_data, test_data]), lookback=60)\n# X_test = X_test[-1].reshape((1, X_test.shape[1], X_test.shape[2]))\n\n# predictions = []\n# for name, model in models.items():\n#     print(f\"Predicting with model: {name}\")\n#     predicted_prices = model.predict(X_test)\n#     predicted_prices = scaler.inverse_transform(predicted_prices)  # Rescale predictions\n#     predicted_high_price, predicted_low_price = predicted_prices[0]\n#     predictions.append([predicted_high_price,predicted_low_price])\n\n# print('predictions',predictions)\n\n# final_prediction = np.mean(predictions, axis=0)[0]\n# predicted_high, predicted_low = final_prediction  \n\n# actual_high = test_data['high'].values[0]\n# actual_low = test_data['low'].values[0]\n\n# print(f\"Prediction Date: {exact_date.date()}\")\n# print(f\"Predicted High Price: {predicted_high:.2f}\")\n# print(f\"Predicted Low Price: {predicted_low:.2f}\")\n# print(f\"Actual High Price: {actual_high:.2f}\")\n# print(f\"Actual Low Price: {actual_low:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:54:19.222973Z","iopub.execute_input":"2024-12-04T18:54:19.223302Z","iopub.status.idle":"2024-12-04T18:54:19.228363Z","shell.execute_reply.started":"2024-12-04T18:54:19.223271Z","shell.execute_reply":"2024-12-04T18:54:19.227307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# plt.figure(figsize=(10, 6))\n# plt.plot(train_data['timestamp'], train_data['high'], label=\"Training Data (High)\")\n# plt.plot(train_data['timestamp'], train_data['low'], label=\"Training Data (Low)\")\n# plt.axvline(x=exact_date, color='r', linestyle='--', label=\"Prediction Date\")\n# plt.scatter(exact_date, predicted_high, color='g', label=\"Predicted High\")\n# plt.scatter(exact_date, predicted_low, color='b', label=\"Predicted Low\")\n# plt.scatter(exact_date, actual_high, color='orange', label=\"Actual High\")\n# plt.scatter(exact_date, actual_low, color='purple', label=\"Actual Low\")\n# plt.legend()\n# plt.title(f\"Stock Price Prediction for {'TSLA'}\")\n# plt.xlabel(\"Date\")\n# plt.ylabel(\"Price\")\n# plt.xticks(rotation=45)\n# plt.tight_layout()\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:54:19.230967Z","iopub.execute_input":"2024-12-04T18:54:19.231290Z","iopub.status.idle":"2024-12-04T18:54:19.244470Z","shell.execute_reply.started":"2024-12-04T18:54:19.231260Z","shell.execute_reply":"2024-12-04T18:54:19.243518Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Boost base modelss ","metadata":{}},{"cell_type":"code","source":"# data = preprocess_stock_data('/kaggle/input/stock-past-one-year-data/stocks.csv', 'CSX')\n# prediction_date = '2024-11-15'\n# prediction_date = pd.to_datetime(prediction_date).normalize()\n\n# try:\n#     exact_date = find_exact_date(data, prediction_date)\n#     print(f\"Using the exact available date: {exact_date.date()} for prediction.\")\n# except ValueError as e:\n#     print(e)\n#     exit()\n\n# # Scaling and data preparation\n# train_data = data[data['timestamp'] < exact_date]\n# test_data = data[data['timestamp'] == exact_date]\n# X_train, y_train, _ = prepare_lstm_data(train_data, lookback=60)\n\n# # Fit the scaler\n# scaler = MinMaxScaler()\n# y_train_scaled = scaler.fit_transform(y_train)\n\n# base_models = {\n#     'dnn_lstm': create_dnn_lstm_model((X_train.shape[1], X_train.shape[2])),\n#     'cnn_lstm': create_cnn_lstm_model((X_train.shape[1], X_train.shape[2])),\n#     'gru_lstm': create_gru_lstm_model((X_train.shape[1], X_train.shape[2])),\n# }\n\n# early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n\n# def boost_model(base_model, X_train, y_train, num_boosts=3):\n#     models = []\n#     residuals = y_train.copy()\n#     model_json = base_model.to_json()\n#     for i in range(num_boosts):\n#         print(f\"Training Boosted Model {i + 1}\")\n#         model = model_from_json(model_json)\n#         model.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error')\n#         model.fit(X_train, residuals, epochs=40, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n#         residuals -= model.predict(X_train)\n#         models.append(model)\n#     return models\n\n# boosted_models = {}\n\n# for name, model in base_models.items():\n#     print(\"******************************************************\")\n#     print(f\"Boosting {name}...\")\n#     boosted_models[name] = boost_model(model, X_train, y_train_scaled)\n\n# # Prepare test data\n# X_test, _, _ = prepare_lstm_data(pd.concat([train_data, test_data]), lookback=60)\n# X_test = X_test[-1].reshape((1, X_test.shape[1], X_test.shape[2]))\n\n# preds = []\n# for name, boosted_model_list in boosted_models.items():\n#     print(f\"Predicting with boosted {name}\")\n#     combined_predictions = np.mean([model.predict(X_test) for model in boosted_model_list], axis=0)\n#     combined_predictions = scaler.inverse_transform(combined_predictions)\n#     predicted_high_price, predicted_low_price = combined_predictions[0]\n#     preds.append([predicted_high_price, predicted_low_price])\n\n# print('Predictions:', preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:54:19.245712Z","iopub.execute_input":"2024-12-04T18:54:19.246042Z","iopub.status.idle":"2024-12-04T18:54:19.260060Z","shell.execute_reply.started":"2024-12-04T18:54:19.245995Z","shell.execute_reply":"2024-12-04T18:54:19.259060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cyclic train","metadata":{}},{"cell_type":"code","source":"def calculate_weighted_average(predictions, weights):\n    \"\"\"\n    Calculate the weighted average for the predictions using the provided weights.\n    predictions: A list of predictions (e.g., [model1_predictions, model2_predictions, model3_predictions])\n    weights: Corresponding weights for each model's predictions\n    \"\"\"\n    weighted_sum = sum([p * w for p, w in zip(predictions, weights)])\n    return weighted_sum\n\ndef calculate_error(predicted_high, predicted_low, actual_high, actual_low):\n    \"\"\"\n    Calculate a simple error metric (e.g., Mean Squared Error) between predicted and actual prices.\n    \"\"\"\n    high_error = (predicted_high - actual_high) ** 2\n    low_error = (predicted_low - actual_low) ** 2\n    return high_error + low_error\n\ndef trainner_and_tester(prediction_date):\n    data = preprocess_stock_data('/kaggle/input/stock-past-one-year-data/stocks.csv', 'TSLA')\n    prediction_date = pd.to_datetime(prediction_date).normalize()\n        \n    try:\n        exact_date = find_exact_date(data, prediction_date)\n        print(f\"Using the exact available date: {exact_date.date()} for prediction.\")\n    except ValueError as e:\n        print(e)\n        exit()\n\n    train_data = data[data['timestamp'] < exact_date]\n    test_data = data[data['timestamp'].dt.normalize() == exact_date]\n    \n    if test_data.empty:\n        raise ValueError(f\"No data available for the prediction date: {exact_date.date()}\")\n        \n    X_train, y_train, scaler = prepare_lstm_data(train_data, lookback=60)\n    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n\n    histories = {}\n    \n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        futures = {\n            executor.submit(train_model, name, model): name \n            for name, model in models.items()\n        }\n        for future in concurrent.futures.as_completed(futures):\n            name, history = future.result()\n            histories[name] = history\n\n    X_test, _, _ = prepare_lstm_data(pd.concat([train_data, test_data]), lookback=60)\n    X_test = X_test[-1].reshape((1, X_test.shape[1], X_test.shape[2]))\n    \n    predictions = [[],[]]\n    for name, model in models.items():\n        print(f\"Predicting with model: {name}\")\n        predicted_prices = model.predict(X_test)  \n        dummy_columns = np.zeros((predicted_prices.shape[0], 2))  \n        predicted_prices_with_dummies = np.hstack([predicted_prices, dummy_columns])\n        predicted_prices_rescaled = scaler.inverse_transform(predicted_prices_with_dummies)\n        predicted_high_price, predicted_low_price = predicted_prices_rescaled[0, 0], predicted_prices_rescaled[0, 1]\n        predictions[0].append(predicted_high_price)\n        predictions[1].append(predicted_low_price)\n\n    possible_weights = [\n    [0.1, 0.1, 0.8],\n    [0.1, 0.2, 0.7],\n    [0.1, 0.3, 0.6],\n    [0.1, 0.4, 0.5],\n    [0.1, 0.5, 0.4],\n    [0.1, 0.6, 0.3],\n    [0.1, 0.7, 0.2],\n    [0.1, 0.8, 0.1],\n    [0.2, 0.1, 0.7],\n    [0.2, 0.2, 0.6],\n    [0.2, 0.3, 0.5],\n    [0.2, 0.4, 0.4],\n    [0.2, 0.5, 0.3],\n    [0.2, 0.6, 0.2],\n    [0.2, 0.7, 0.1],\n    [0.3, 0.1, 0.6],\n    [0.3, 0.2, 0.5],\n    [0.3, 0.3, 0.4],\n    [0.3, 0.4, 0.3],\n    [0.3, 0.5, 0.2],\n    [0.3, 0.6, 0.1],\n    [0.4, 0.1, 0.5],\n    [0.4, 0.2, 0.4],\n    [0.4, 0.3, 0.3],\n    [0.4, 0.4, 0.2],\n    [0.4, 0.5, 0.1],\n    [0.5, 0.1, 0.4],\n    [0.5, 0.2, 0.3],\n    [0.5, 0.3, 0.2],\n    [0.5, 0.4, 0.1],\n    [0.6, 0.1, 0.3],\n    [0.6, 0.2, 0.2],\n    [0.6, 0.3, 0.1],\n    [0.7, 0.1, 0.2],\n    [0.7, 0.2, 0.1],\n    [0.8, 0.1, 0.1]\n]\n\n    actual_high = test_data['high'].values[0]\n    actual_low = test_data['low'].values[0]\n    \n    best_weights = None\n    best_error = float('inf')\n    best_predicted_high = 0\n    best_predicted_low = 0\n    \n    for weights in possible_weights:\n        weighted_high = calculate_weighted_average(predictions[0], weights)\n        weighted_low = calculate_weighted_average(predictions[1], weights)\n        \n        error = calculate_error(weighted_high, weighted_low, actual_high, actual_low)\n        \n        if error < best_error:\n            best_error = error\n            best_weights = weights\n            best_predicted_high = weighted_high\n            best_predicted_low = weighted_low\n\n    mean_high_prediction = np.mean(predictions[0])\n    mean_low_prediction = np.mean(predictions[1])\n\n    return (\n        predictions , exact_date.date(), best_weights,best_predicted_high, mean_high_prediction,best_predicted_low, mean_low_prediction,actual_high, actual_low\n    )\n\npredictions ,exact_date,best_weights, best_predicted_high, mean_high_prediction,best_predicted_low, mean_low_prediction,actual_high, actual_low = trainner_and_tester('2024-12-02')\n\nprint(f\"\\nPrediction Date: {exact_date}\")\nprint(f\"\\best weights: {best_weights}\")\nprint(f\"Best Predicted High: {best_predicted_high:.2f}\")\nprint(f\"Best Predicted Low: {best_predicted_low:.2f}\")\nprint(f\"mean Predicted High: {mean_high_prediction:.2f}\")\nprint(f\"mean Predicted Low: {mean_low_prediction:.2f}\")\nprint(f\"Actual High Price: {actual_high:.2f}\")\nprint(f\"Actual Low Price: {actual_low:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:54:19.261345Z","iopub.execute_input":"2024-12-04T18:54:19.261821Z","iopub.status.idle":"2024-12-04T18:54:54.813963Z","shell.execute_reply.started":"2024-12-04T18:54:19.261773Z","shell.execute_reply":"2024-12-04T18:54:54.813079Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# mass test","metadata":{}},{"cell_type":"code","source":"# Get the last 10 dates from the dataset\ndatatail = data.tail(300)\ndate_list = datatail['timestamp'].dt.strftime('%Y-%m-%d').tolist()\nprint(date_list)\n\n# Initialize an empty list to store the results\nresults = []\n\n# Iterate through each date and get the predictions\nfor date in date_list:\n    perdictions , exact_date, best_weights, best_predicted_high, mean_high_prediction, best_predicted_low, mean_low_prediction, actual_high, actual_low = trainner_and_tester(date)\n    \n    result = {\n        'Prediction Date': exact_date,\n        'Best Predicted High': best_predicted_high,\n        'Best Predicted Low': best_predicted_low,\n        'Mean Predicted High': mean_high_prediction,\n        'Mean Predicted Low': mean_low_prediction,\n        'Actual High': actual_high,\n        'Actual Low': actual_low,\n        'dnn_lstm_low':predictions[0][0],\n        'cnn_lstm_low':predictions[0][1],\n        'gru_lstm_low':predictions[0][2],\n        'dnn_lstm_high':predictions[1][0],\n        'cnn_lstm_high':predictions[1][1],\n        'gnn_lstm_high':predictions[1][2],\n    }\n    results.append(result)\n\n# Convert results to a DataFrame\nresultsdf = pd.DataFrame(results)\n\n# Display the results\nresultsdf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:54:54.815174Z","iopub.execute_input":"2024-12-04T18:54:54.815535Z","iopub.status.idle":"2024-12-04T18:56:36.359294Z","shell.execute_reply.started":"2024-12-04T18:54:54.815467Z","shell.execute_reply":"2024-12-04T18:56:36.358234Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resultsdf.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:56:36.360550Z","iopub.execute_input":"2024-12-04T18:56:36.360930Z","iopub.status.idle":"2024-12-04T18:56:36.367645Z","shell.execute_reply.started":"2024-12-04T18:56:36.360898Z","shell.execute_reply":"2024-12-04T18:56:36.366562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"actual_highs = resultsdf['Actual High']\nactual_lows = resultsdf['Actual Low']\n\n# Predicted values for each model\ndnn_lstm_low = resultsdf['dnn_lstm_low']\ncnn_lstm_low = resultsdf['cnn_lstm_low']\ngru_lstm_low = resultsdf['gru_lstm_low']\ndnn_lstm_high = resultsdf['dnn_lstm_high']\ncnn_lstm_high = resultsdf['cnn_lstm_high']\ngru_lstm_high = resultsdf['gnn_lstm_high']\n\nmean_predicted_highs = resultsdf['Mean Predicted High']\nmean_predicted_lows = resultsdf['Mean Predicted Low']\nweighted_predicted_highs = resultsdf['Best Predicted High']\nweighted_predicted_lows = resultsdf['Best Predicted Low']\n\n# Calculate RMSE and MAE for each model prediction (both high and low prices)\ndef calculate_metrics(actuals, predicted):\n    rmse = np.sqrt(mean_squared_error(actuals, predicted))\n    mae = mean_absolute_error(actuals, predicted)\n    return rmse, mae\n\n# For High Prices\nrmse_dnn_lstm_high, mae_dnn_lstm_high = calculate_metrics(actual_highs, dnn_lstm_high)\nrmse_cnn_lstm_high, mae_cnn_lstm_high = calculate_metrics(actual_highs, cnn_lstm_high)\nrmse_gru_lstm_high, mae_gru_lstm_high = calculate_metrics(actual_highs, gru_lstm_high)\nrmse_mean_high, mae_mean_high = calculate_metrics(actual_highs, mean_predicted_highs)\nrmse_weighted_high, mae_weighted_high = calculate_metrics(actual_highs, weighted_predicted_highs)\n\n# For Low Prices\nrmse_dnn_lstm_low, mae_dnn_lstm_low = calculate_metrics(actual_lows, dnn_lstm_low)\nrmse_cnn_lstm_low, mae_cnn_lstm_low = calculate_metrics(actual_lows, cnn_lstm_low)\nrmse_gru_lstm_low, mae_gru_lstm_low = calculate_metrics(actual_lows, gru_lstm_low)\nrmse_mean_low, mae_mean_low = calculate_metrics(actual_lows, mean_predicted_lows)\nrmse_weighted_low, mae_weighted_low = calculate_metrics(actual_lows, weighted_predicted_lows)\n\n# Print the results for each model\nprint(\"\\nRegression Metrics for DNN LSTM Model (High Prices):\")\nprint(f\"RMSE: {rmse_dnn_lstm_high:.2f}\")\nprint(f\"MAE: {mae_dnn_lstm_high:.2f}\")\n\nprint(\"\\nRegression Metrics for CNN LSTM Model (High Prices):\")\nprint(f\"RMSE: {rmse_cnn_lstm_high:.2f}\")\nprint(f\"MAE: {mae_cnn_lstm_high:.2f}\")\n\nprint(\"\\nRegression Metrics for GRU LSTM Model (High Prices):\")\nprint(f\"RMSE: {rmse_gru_lstm_high:.2f}\")\nprint(f\"MAE: {mae_gru_lstm_high:.2f}\")\n\nprint(\"\\nRegression Metrics for Mean Model (High Prices):\")\nprint(f\"RMSE: {rmse_mean_high:.2f}\")\nprint(f\"MAE: {mae_mean_high:.2f}\")\n\nprint(\"\\nRegression Metrics for Weighted Model (High Prices):\")\nprint(f\"RMSE: {rmse_weighted_high:.2f}\")\nprint(f\"MAE: {mae_weighted_high:.2f}\")\n\nprint(\"\\nRegression Metrics for DNN LSTM Model (Low Prices):\")\nprint(f\"RMSE: {rmse_dnn_lstm_low:.2f}\")\nprint(f\"MAE: {mae_dnn_lstm_low:.2f}\")\n\nprint(\"\\nRegression Metrics for CNN LSTM Model (Low Prices):\")\nprint(f\"RMSE: {rmse_cnn_lstm_low:.2f}\")\nprint(f\"MAE: {mae_cnn_lstm_low:.2f}\")\n\nprint(\"\\nRegression Metrics for GRU LSTM Model (Low Prices):\")\nprint(f\"RMSE: {rmse_gru_lstm_low:.2f}\")\nprint(f\"MAE: {mae_gru_lstm_low:.2f}\")\n\nprint(\"\\nRegression Metrics for Mean Model (Low Prices):\")\nprint(f\"RMSE: {rmse_mean_low:.2f}\")\nprint(f\"MAE: {mae_mean_low:.2f}\")\n\nprint(\"\\nRegression Metrics for Weighted Model (Low Prices):\")\nprint(f\"RMSE: {rmse_weighted_low:.2f}\")\nprint(f\"MAE: {mae_weighted_low:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:56:36.369625Z","iopub.execute_input":"2024-12-04T18:56:36.370145Z","iopub.status.idle":"2024-12-04T18:56:36.396851Z","shell.execute_reply.started":"2024-12-04T18:56:36.370093Z","shell.execute_reply":"2024-12-04T18:56:36.395707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure the 'Prediction Date' column is in datetime format\nresultsdf['Prediction Date'] = pd.to_datetime(resultsdf['Prediction Date'])\n\n# Create the plot with all models in a single graph\nplt.figure(figsize=(12, 8))\n\n# Plot for DNN LSTM Model\nplt.plot(resultsdf['Prediction Date'], resultsdf['dnn_lstm_high'], label=\"DNN LSTM Predicted High\", color='r', marker='o')\nplt.plot(resultsdf['Prediction Date'], resultsdf['dnn_lstm_low'], label=\"DNN LSTM Predicted Low\", color='r', marker='*')\n\n# Plot for CNN LSTM Model\nplt.plot(resultsdf['Prediction Date'], resultsdf['cnn_lstm_high'], label=\"CNN LSTM Predicted High\", color='b', marker='o')\nplt.plot(resultsdf['Prediction Date'], resultsdf['cnn_lstm_low'], label=\"CNN LSTM Predicted Low\", color='b', marker='*')\n\n# Plot for GRU LSTM Model\nplt.plot(resultsdf['Prediction Date'], resultsdf['gnn_lstm_high'], label=\"GRU LSTM Predicted High\", color='g', marker='o')\nplt.plot(resultsdf['Prediction Date'], resultsdf['gru_lstm_low'], label=\"GRU LSTM Predicted Low\", color='g', marker='*')\n\n# Plot for Mean Model\nplt.plot(resultsdf['Prediction Date'], resultsdf['Mean Predicted High'], label=\"Mean Predicted High\", color='c', marker='o')\nplt.plot(resultsdf['Prediction Date'], resultsdf['Mean Predicted Low'], label=\"Mean Predicted Low\", color='c', marker='*')\n\n# Plot for Weighted Model\nplt.plot(resultsdf['Prediction Date'], resultsdf['Best Predicted High'], label=\"Weighted Predicted High\", color='m', marker='o')\nplt.plot(resultsdf['Prediction Date'], resultsdf['Best Predicted Low'], label=\"Weighted Predicted Low\", color='m', marker='*')\n\n# Plot for Actual High and Low\nplt.plot(resultsdf['Prediction Date'], resultsdf['Actual High'], label=\"Actual High\", color='orange', marker='o')\nplt.plot(resultsdf['Prediction Date'], resultsdf['Actual Low'], label=\"Actual Low\", color='orange', marker='*')\n\n# Adding title, labels, and legend\nplt.title(f\"Stock Price Prediction (All Models) for TSLA\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Price\")\nplt.xticks(rotation=45)\nplt.legend()\n\nplt.tight_layout()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:56:36.398443Z","iopub.execute_input":"2024-12-04T18:56:36.398776Z","iopub.status.idle":"2024-12-04T18:56:37.126412Z","shell.execute_reply.started":"2024-12-04T18:56:36.398747Z","shell.execute_reply":"2024-12-04T18:56:37.125458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resultsdf.to_csv(\"prepareforsttack.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-04T18:56:37.127573Z","iopub.execute_input":"2024-12-04T18:56:37.127873Z","iopub.status.idle":"2024-12-04T18:56:37.137350Z","shell.execute_reply.started":"2024-12-04T18:56:37.127844Z","shell.execute_reply":"2024-12-04T18:56:37.136409Z"}},"outputs":[],"execution_count":null}]}